{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "import vertexai\n",
    "from vertexai.preview.generative_models import GenerativeModel, Part, SafetySetting\n",
    "import vertexai.preview.generative_models as generative_models\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file = \"\"\n",
    "output_file = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vertex_project = os.environ['VERTEX_PROJECT_ID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(prompt):\n",
    "  vertexai.init(project=vertex_project, location=\"us-central1\")\n",
    "  model = GenerativeModel(\"gemini-1.5-pro-002\")\n",
    "  responses = model.generate_content(\n",
    "    prompt,\n",
    "    generation_config={\n",
    "        \"max_output_tokens\": 1000,\n",
    "        \"temperature\": 0.4,\n",
    "        \"top_p\": 1\n",
    "    },\n",
    "    safety_settings = [\n",
    "        SafetySetting(\n",
    "            category=SafetySetting.HarmCategory.HARM_CATEGORY_HATE_SPEECH,\n",
    "            threshold=SafetySetting.HarmBlockThreshold.OFF\n",
    "        ),\n",
    "        SafetySetting(\n",
    "            category=SafetySetting.HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT,\n",
    "            threshold=SafetySetting.HarmBlockThreshold.OFF\n",
    "        ),\n",
    "        SafetySetting(\n",
    "            category=SafetySetting.HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT,\n",
    "            threshold=SafetySetting.HarmBlockThreshold.OFF\n",
    "        ),\n",
    "        SafetySetting(\n",
    "            category=SafetySetting.HarmCategory.HARM_CATEGORY_HARASSMENT,\n",
    "            threshold=SafetySetting.HarmBlockThreshold.OFF\n",
    "        ),\n",
    "    ],\n",
    "    stream=False,\n",
    "  )\n",
    "  \n",
    "  return responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(input_file)\n",
    "\n",
    "\n",
    "print(len(df))\n",
    "print()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_prompt(fato_relevante, analise):\n",
    "    resp = f'''### Instruções:\n",
    "    Você receberá dois documentos: \"Documento 1\" e \"Documento 2\". Sua tarefa é analisar o conteúdo de ambos e determinar a natureza da relação entre eles. \n",
    "    \n",
    "    ### Opções de Resposta:\n",
    "    Referência Explícita: O \"Documento 2\" cita explicitamente os mesmos eventos específicos tratados no \"Documento 1\", seja através de citações diretas ou paráfrases claras.\n",
    "    Sem Referência: O \"Documento 2\" não faz referência alguma aos eventos específicos tratados no \"Documento 1\".\n",
    "\n",
    "    ### Formato de Saída:\n",
    "    resposta: [Referência Explícita/Sem Referência]\n",
    "    trechos que confirmem a resposta: [Trechos relevantes de ambos os documentos que suportam sua resposta]\n",
    "    \n",
    "    ### Documento 1\n",
    "    {fato_relevante}\n",
    "    \n",
    "    ### Documento 2\n",
    "    {analise}'''\n",
    "    \n",
    "    return resp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import unicodedata\n",
    "\n",
    "def remover_acentos(texto):\n",
    "    texto_normalizado = unicodedata.normalize('NFD', texto)\n",
    "    return ''.join([c for c in texto_normalizado if not unicodedata.combining(c)])\n",
    "\n",
    "def verificar_referencia(texto):\n",
    "    texto = remover_acentos(texto)\n",
    "    \n",
    "    match = re.search(r\"resposta:\\s*(.*?)\\s*(trechos que|$)\", texto, re.IGNORECASE)\n",
    "    if not match:\n",
    "        return \"Nenhum padrão de resposta encontrado.\"\n",
    "    \n",
    "    resposta = match.group(1).strip().lower()\n",
    "    \n",
    "    if \"referencia explicita\" in resposta:\n",
    "        return \"referencia explicita\"\n",
    "    elif \"referencia implicita\" in resposta:\n",
    "        return \"referencia implicita\"\n",
    "    elif \"referencia complementar\" in resposta:\n",
    "        return \"referencia complementar\"\n",
    "    elif \"referencia especulativa\" in resposta:\n",
    "        return \"referencia especulativa\"\n",
    "    elif \"sem referencia\" in resposta:\n",
    "        return \"sem referencia\"\n",
    "    else:\n",
    "        return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answers = [\"none\"] * len(df)\n",
    "y_pred = [-1] * len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "\n",
    "while i < len(df):\n",
    "  try:\n",
    "    prompt = construct_prompt(df[\"AN_conteudo\"].iloc[i], df[\"FR_conteudo\"].iloc[i])\n",
    "\n",
    "    resp = generate(prompt)\n",
    "\n",
    "    resp_texto = resp.text.replace(\"\\n\", '')\n",
    "    answers[i] = resp_texto.lower()\n",
    "    y_pred[i] = verificar_referencia(resp_texto)\n",
    "    \n",
    "    i += 1\n",
    "\n",
    "    if i % 50 == 0:\n",
    "        print(\"Progresso: \", i)\n",
    "\n",
    "    # Pausa de 2 segundos (sugerido é 1 solicitação a cada 5s)\n",
    "    time.sleep(2)\n",
    "\n",
    "  except Exception as e:\n",
    "    erro = f\"Erro encontrado: {e}. Tentando novamente...\"\n",
    "    print(erro)\n",
    "    \n",
    "    answers[i] = erro\n",
    "\n",
    "    i += 1\n",
    "    \n",
    "    time.sleep(5)  # Pausa antes de tentar novamente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "errors = [i for i, v in enumerate(y_pred) if isinstance(v, (int, float)) and v == -1]\n",
    "\n",
    "print(errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in errors:\n",
    "  try:\n",
    "    prompt = construct_prompt(df[\"pdf_text\"].iloc[i], df[\"dates\"].iloc[i], df[\"content\"].iloc[i], df[\"fr_date2\"].iloc[i])\n",
    "\n",
    "    resp = generate(prompt)\n",
    "\n",
    "    resp_texto = resp.text.replace(\"\\n\", '')\n",
    "    answers[i] = resp_texto.lower()\n",
    "    y_pred[i] = verificar_referencia(resp_texto)\n",
    "    \n",
    "    i += 1\n",
    "\n",
    "    if i % 50 == 0:\n",
    "        print(\"Progresso: \", i)\n",
    "\n",
    "    # Pausa de 2 segundos (sugerido é 1 solicitação a cada 5s)\n",
    "    time.sleep(3)\n",
    "\n",
    "  except Exception as e:\n",
    "    erro = f\"Erro encontrado: {e}. Tentando novamente...\"\n",
    "    print(erro)\n",
    "    \n",
    "    answers[i] = erro\n",
    "\n",
    "    i += 1\n",
    "    \n",
    "    time.sleep(5)  # Pausa antes de tentar novamente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors = [i for i, v in enumerate(y_pred) if isinstance(v, (int, float)) and v == -1]\n",
    "\n",
    "print(errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Contagem de 'referencia explicita':\", y_pred.count(\"referencia explicita\"))\n",
    "print(\"Contagem de 'referencia implicita':\", y_pred.count(\"referencia implicita\"))\n",
    "print(\"Contagem de 'referencia complementar':\", y_pred.count(\"referencia complementar\"))\n",
    "print(\"Contagem de 'referencia especulativa':\", y_pred.count(\"referencia especulativa\"))\n",
    "print(\"Contagem de 'sem referencia':\", y_pred.count(\"sem referencia\"))\n",
    "print(\"Contagem de respostas não classificadas (-1):\", y_pred.count(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"pred\"] = y_pred\n",
    "df[\"responses_raw\"] = answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(output_file, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
