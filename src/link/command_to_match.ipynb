{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "import cohere\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file = \"\"\n",
    "output_file = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "co = cohere.Client(os.environ['COHERE_API'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(prompt):\n",
    "  response = co.chat(\n",
    "    model=\"command-r-plus\",\n",
    "    temperature=0.4,\n",
    "    p = 0.99,\n",
    "    max_tokens=1000,\n",
    "    seed=42,\n",
    "    message=prompt\n",
    "  )\n",
    "  return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(input_file)\n",
    "\n",
    "\n",
    "print(len(df))\n",
    "print()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_prompt(fato_relevante, data_fato, analise, data_analise):\n",
    "    resp = f'''### Instruções:\n",
    "    Você receberá dois documentos: \"Documento 1\" e \"Documento 2\". Sua tarefa é analisar o conteúdo de ambos e determinar a natureza da relação entre eles. \n",
    "    \n",
    "    ### Opções de Resposta:\n",
    "    Referência Explícita: O \"Documento 2\" cita explicitamente os mesmos eventos específicos tratados no \"Documento 1\", seja através de citações diretas ou paráfrases claras.\n",
    "    Sem Referência: O \"Documento 2\" não faz referência alguma aos eventos específicos tratados no \"Documento 1\".\n",
    "\n",
    "    ### Formato de Saída:\n",
    "    resposta: [Referência Explícita/Sem Referência]\n",
    "    trechos que confirmem a resposta: [Trechos relevantes de ambos os documentos que suportam sua resposta]\n",
    "    \n",
    "    ### Documento 1\n",
    "    {fato_relevante}\n",
    "    \n",
    "    ### Documento 2\n",
    "    {analise}'''\n",
    "    \n",
    "    return resp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import unicodedata\n",
    "\n",
    "def remover_acentos(texto):\n",
    "    texto_normalizado = unicodedata.normalize('NFD', texto)\n",
    "    return ''.join([c for c in texto_normalizado if not unicodedata.combining(c)])\n",
    "\n",
    "def verificar_referencia(texto):\n",
    "    texto = remover_acentos(texto)\n",
    "    \n",
    "    match = re.search(r\"resposta:\\s*(.*?)\\s*(trechos que|$)\", texto, re.IGNORECASE)\n",
    "    if not match:\n",
    "        return \"Nenhum padrão de resposta encontrado.\"\n",
    "    \n",
    "    resposta = match.group(1).strip().lower()\n",
    "    \n",
    "    if \"referencia explicita\" in resposta:\n",
    "        return \"referencia explicita\"\n",
    "    elif \"referencia implicita\" in resposta:\n",
    "        return \"referencia implicita\"\n",
    "    elif \"referencia complementar\" in resposta:\n",
    "        return \"referencia complementar\"\n",
    "    elif \"referencia especulativa\" in resposta:\n",
    "        return \"referencia especulativa\"\n",
    "    elif \"sem referencia\" in resposta:\n",
    "        return \"sem referencia\"\n",
    "    else:\n",
    "        return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answers = [\"none\"] * len(df)\n",
    "y_pred = [-1] * len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "\n",
    "while i < len(df):\n",
    "  try:\n",
    "    prompt = construct_prompt(df[\"pdf_text\"].iloc[i], df[\"dates\"].iloc[i], df[\"content\"].iloc[i], df[\"fr_date2\"].iloc[i])\n",
    "\n",
    "    resp = generate(prompt)\n",
    "\n",
    "    resp_texto = resp.text\n",
    "    answers[i] = resp_texto.lower()\n",
    "    y_pred[i] = verificar_referencia(resp_texto)\n",
    "    \n",
    "    i += 1\n",
    "    \n",
    "    if i % 50 == 0:\n",
    "        print(\"Progresso: \", i)\n",
    "\n",
    "    # Pausa de 2 segundos (sugerido é 1 solicitação a cada 5s)\n",
    "    time.sleep(2)\n",
    "\n",
    "  except Exception as e:\n",
    "    erro = f\"Erro encontrado: {e}. Tentando novamente...\"\n",
    "    print(erro)\n",
    "    \n",
    "    answers[i] = erro\n",
    "\n",
    "    i += 1\n",
    "    \n",
    "    time.sleep(5)  # Pausa antes de tentar novamente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "errors = [i for i, v in enumerate(y_pred) if isinstance(v, (int, float)) and v == -1]\n",
    "\n",
    "print(errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Contagem de 'referencia explicita':\", y_pred.count(\"referencia explicita\"))\n",
    "print(\"Contagem de 'referencia implicita':\", y_pred.count(\"referencia implicita\"))\n",
    "print(\"Contagem de 'referencia complementar':\", y_pred.count(\"referencia complementar\"))\n",
    "print(\"Contagem de 'referencia especulativa':\", y_pred.count(\"referencia especulativa\"))\n",
    "print(\"Contagem de 'sem referencia':\", y_pred.count(\"sem referencia\"))\n",
    "print(\"Contagem de respostas não classificadas (-1):\", y_pred.count(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"pred\"] = y_pred\n",
    "df[\"responses_raw\"] = answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(output_file, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
